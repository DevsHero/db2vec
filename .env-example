# --- File and Database Type ---
# Path to the .sql/.surql database dump file to process
FILE_PATH="./surreal.surql"
# Vector database type (redis|chroma|milvus|qdrant|surreal|pinecone)
TYPE="redis"

# --- Authentication ---
# Username for database authentication (Milvus, SurrealDB)
USER="root"
# Password for database authentication (Milvus, SurrealDB, Redis)
PASS=""
# API key/token for database authentication (Chroma, Qdrant, Pinecone, Google Gemini)
SECRET=""
# Enable authentication for the vector database (true/false)
AUTH="false"

# --- Connection Details ---
# Vector database URL/host endpoint (e.g. redis://127.0.0.1:6379)
VECTOR_HOST="redis://127.0.0.1:6379"
# Target database/collection name (Chroma, Milvus, Qdrant, SurrealDB)
DATABASE="default_database"
# For Pinecone, the name of the index to use
INDEXES="default_indexes"
# Cloud provider for Pinecone (aws, azure, gcp)
CLOUD="aws"
# Cloud region for Pinecone (us-east-1, us-west-1, etc.)
REGION="us-east-1"
# Tenant name for multi-tenant DBs (Chroma)
TENANT="default_tenant"
# Namespace for databases that support it (SurrealDB, Pinecone)
NAMESPACE="default_namespace"

# --- Vector Settings ---
# Vector dimension size (must match embedding model output!)
DIMENSION="768"
# Distance metric for vector similarity (l2|ip|cosine|euclidean|dotproduct)
METRIC="cosine"

# --- Batch Processing ---
# Maximum payload size in MB for database requests
PAYLOAD_SIZE_MB="12"
# Number of records per batch insert into the vector database
CHUNK_SIZE="10"

# --- Embedding Configuration ---
# Embedding provider to use (ollama|tei|google)
EMBEDDING_PROVIDER="ollama"
# Embedding model to use (e.g., nomic-embed-text, text-embedding-004, nomic-embed-text-v2-moe)
EMBEDDING_MODEL="nomic-embed-text"
# Optional: URL endpoint for Ollama or Google embeddings (e.g., http://localhost:11434)
EMBEDDING_URL=""
# API Key for Google Gemini (required if EMBEDDING_PROVIDER='google')
# EMBEDDING_API_KEY=""
# Optional: Task type for Google Gemini API (e.g., SEMANTIC_SIMILARITY)
EMBEDDING_TASK_TYPE="SEMANTIC_SIMILARITY"
# Maximum parallel embedding requests
EMBEDDING_MAX_CONCURRENCY="4"
# Number of texts per embedding batch request
EMBEDDING_BATCH_SIZE="16"
# Maximum tokens for text truncation (provider-specific)
EMBEDDING_MAX_TOKENS="8000"
# Timeout (seconds) for embedding calls (Ollama / TEI)
OLLAMA_TIMEOUT="60"

# --- TEI Binary ---
# Path to TEI binary (tei-metal or tei-onnx).  
# If omitted, the embedded TEI will be extracted & launched.
TEI_BINARY_PATH="tei/tei-metal"

# --- Performance ---
# CPU threads for parallel processing (0 = auto-detect)
NUM_THREADS="0"

# --- Special Behaviors ---
# Enable debug mode to print parsed records (true/false)
DEBUG="false"
# Group Redis records by table name (true/false)
GROUP_REDIS="false"
```# filepath: .env-example

# --- File and Database Type ---
# Path to the .sql/.surql database dump file to process
FILE_PATH="./surreal.surql"
# Vector database type (redis|chroma|milvus|qdrant|surreal|pinecone)
TYPE="redis"

# --- Authentication ---
# Username for database authentication (Milvus, SurrealDB)
USERroot"
# Password for database authentication (Milvus, SurrealDB, Redis)
PASS=""
# API key/token for database authentication (Chroma, Qdrant, Pinecone, Google Gemini)
SECRET=""
# Enable authentication for the vector database (true/false)
AUTH="false"

# --- Connection Details ---
# Vector database URL/host endpoint (e.g. redis://127.0.0.1:6379)
VECTOR_HOST="redis://127.0.0.1:6379"
# Target database/collection name (Chroma, Milvus, Qdrant, SurrealDB)
DATABASE="default_database"
# For Pinecone, the name of the index to use
INDEXES="default_indexes"
# Cloud provider for Pinecone (aws, azure, gcp)
CLOUD="aws"
# Cloud region for Pinecone (us-east-1, us-west-1, etc.)
REGION="us-east-1"
# Tenant name for multi-tenant DBs (Chroma)
TENANT="default_tenant"
# Namespace for databases that support it (SurrealDB, Pinecone)
NAMESPACE="default_namespace"

# --- Vector Settings ---
# Vector dimension size (must match embedding model output!)
DIMENSION="768"
# Distance metric for vector similarity (l2|ip|cosine|euclidean|dotproduct)
METRIC="cosine"

# --- Batch Processing ---
# Maximum payload size in MB for database requests
PAYLOAD_SIZE_MB="12"
# Number of records per batch insert into the vector database
CHUNK_SIZE="10"

# --- Embedding Configuration ---
# Embedding provider to use (ollama|tei|google)
EMBEDDING_PROVIDER="ollama"
# Embedding model to use (e.g., nomic-embed-text, text-embedding-004, nomic-embed-text-v2-moe)
EMBEDDING_MODEL="nomic-embed-text"
# Optional: URL endpoint for Ollama or Google embeddings (e.g., http://localhost:11434)
EMBEDDING_URL=""
# API Key for Google Gemini (required if EMBEDDING_PROVIDER='google')
# EMBEDDING_API_KEY=""
# Optional: Task type for Google Gemini API (e.g., SEMANTIC_SIMILARITY)
EMBEDDING_TASK_TYPE="SEMANTIC_SIMILARITY"
# Maximum parallel embedding requests
EMBEDDING_MAX_CONCURRENCY="4"
# Number of texts per embedding batch request
EMBEDDING_BATCH_SIZE="16"
# Maximum tokens for text truncation (provider-specific)
EMBEDDING_MAX_TOKENS="8000"
# Timeout (seconds) for embedding calls (Ollama / TEI)
OLLAMA_TIMEOUT="60"

# --- TEI Binary ---
# Path to TEI binary (tei-metal or tei-onnx).  
# If omitted, the embedded TEI will be extracted & launched.
TEI_BINARY_PATH="tei/tei-metal"

# --- Performance ---
# CPU threads for parallel processing (0 = auto-detect)
NUM_THREADS="0"

# --- Special Behaviors ---
# Enable debug mode to print parsed records (true/false)
DEBUG="false"
# Group Redis records by table name (true/false)
GROUP_REDIS="false"